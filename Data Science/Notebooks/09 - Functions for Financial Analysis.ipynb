{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"120\" src=\"../Images/supplier-logo.png\">\n",
    "<img style=\"float: left; margin-top: 0\" width=\"80\" src=\"../Images/client-logo.png\">\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "Some of the following content is quite advanced\n",
    "\n",
    "Do not panic about this, just be aware that there are some very fast and efficient libraries available for number crunching using python.\n",
    "\n",
    "This notebook will explain the following topics and concepts:\n",
    "\n",
    "- **Built in Statistical Functions** \n",
    "\n",
    "- **Correlation & Covariance**\n",
    "\n",
    "- **Function application**\n",
    "  - Applying a function to rows of a DataFrame\n",
    "\n",
    "- **Common Front Office Calculations**\n",
    "  - Normalized prices\n",
    "  - the log of returns\n",
    "  - Daily Percentage Change\n",
    "  - Cumulative returns\n",
    "  - macd - Moving Average Convergence/Divergence\n",
    "\n",
    "- **Measuring Performance**\n",
    "  - the %timeit magic\n",
    "  - numpy and numexpr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built in Statistical Functions\n",
    "\n",
    "The following functions can all be applied to a Series.\n",
    "\n",
    "As a column is a Series, they can all be applied to a column or columns of a DataFrame or even an entire DataFrame\n",
    "\n",
    "- Simple Functions\n",
    "- Accumulators\n",
    "- General Purpose Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Functions\n",
    "\n",
    "\n",
    "- count() \n",
    "- min() \n",
    "- max() \n",
    "- sum() \n",
    "- mean()\n",
    "- median() \n",
    "- std() \n",
    "- describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a demonstration Series and call some of it's aggregation functions\n",
    "tmp = pd.Series([13, 2, 4, 24, 9, 25, 6, 50])\n",
    "\n",
    "# Use print to display the result of each function\n",
    "\n",
    "print('count:', tmp.count())\n",
    "print('min:', tmp.min())\n",
    "print('max:', tmp.max())\n",
    "print('sum:', tmp.sum())\n",
    "print('mean:', tmp.mean())\n",
    "print('median:', tmp.median())\n",
    "print('std:', tmp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe() gives a number of statistical values in one function\n",
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accumulators\n",
    "\n",
    "- cumsum()\n",
    "- cummin()\n",
    "- cummax()\n",
    "- cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use print to display the result of each function ('\\n' inserts a new line for readability)\n",
    "\n",
    "print('cumsum:\\n', tmp.cumsum())\n",
    "print('\\ncummin:\\n', tmp.cummin())\n",
    "print('\\ncummax:\\n', tmp.cummax())\n",
    "print('\\ncumprod:\\n', tmp.cumprod())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General purpose Functions\n",
    "\n",
    "There are also a few general purpose functions\n",
    "\n",
    "- diff()  - difference between adjacent values\n",
    "- pct_change() - percentage change between adjacent values\n",
    "- idxmin() - numerical index of minimum value in series (Series begin at index 0)\n",
    "- idxmax() - numerical index of maximum value in series\n",
    "- skew()\n",
    "- kurt()\n",
    "- quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use print to display the result of each function ('\\n' inserts a new line for readability)\n",
    "\n",
    "print('diff:\\n', tmp.diff())\n",
    "print('\\npct_change:\\n', tmp.pct_change())\n",
    "print('\\nidxmin:', tmp.idxmin())\n",
    "print('idxmax:', tmp.idxmax())\n",
    "print('skew:', tmp.skew())\n",
    "print('kurt:', tmp.kurt())\n",
    "print('quantile:', tmp.quantile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Front Office Calculations\n",
    "\n",
    "\n",
    "**Common Front Office Calculations**\n",
    "- Normalized prices\n",
    "- the log of returns\n",
    "- Daily Percentage Change\n",
    "- Cumulative returns\n",
    "- macd - Moving Average Convergence/Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load in the famous FANG stocks, make sure the index is the Date and it's sorted ascending\n",
    "df_FB = pd.read_excel(io='../Data/market_data.xls', sheet_name='FB', parse_dates=True, index_col='Date')\n",
    "df_AMZN = pd.read_excel(io='../Data/market_data.xls', sheet_name='AMZN', parse_dates=True, index_col='Date')\n",
    "df_AAPL = pd.read_excel(io='../Data/market_data.xls', sheet_name='AAPL', parse_dates=True, index_col='Date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Look at the  Closing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['FB'] = df_FB['Close']\n",
    "\n",
    "df['FB'].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Look at Normalized Prices\n",
    "\n",
    "The difference between price(t0) and price (t+1)\n",
    "\n",
    "This is the same as cumulative daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NormdP'] = df['FB']/df.iloc[0]['FB']\n",
    "\n",
    "df['NormdP'].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Look at the Log of the Daily Returns\n",
    "\n",
    "- When calculating the return of an investment or position, an accumulation of the log of daily returns is used.\n",
    "\n",
    "- This allows a direct comparison to be made between different instruments\n",
    "\n",
    "- When backtesting technical analysis you will be employing this measure to compare a simple trading strategy against market performance.\n",
    "\n",
    "- This is a very simple value to arrive at\n",
    "\n",
    "- log (price / price(t-1))\n",
    "\n",
    "- Use a combination of np.log and the time shift functions\n",
    "\n",
    "- Use the **cumsum()** function to arrive at the payoff\n",
    "\n",
    "- Where there is a choice between adjusted and unadjusted, use the Adjusted values (e.g. AdjOpen, AdjVolume, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns for Facebook\n",
    "# Have the Adjusted Close so use that\n",
    "df['Log Returns'] = np.log(df['FB'] / df['FB'].shift(1))\n",
    "\n",
    "# Plot returns for both for a direct comparison\n",
    "# applying the exponential function to the accumulator\n",
    "# Very very common in financial analysis\n",
    "df['Log Returns'].cumsum().apply(np.exp).plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Look at Cumulative Returns\n",
    "\n",
    "The formula for a cumulative daily return is:\n",
    "\n",
    "$ i_i = (1+r_t) * i_{t-1} $\n",
    "\n",
    "Reached by multiplying previous investment at i at t-1 by 1+ percent returns. <BR>\n",
    "Easy to calculate using pandas with its `cumprod()` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cumulative Return'] = (1 + df['Pct Chg']).cumprod()\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "df['Cumulative Return'].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Percentage Change\n",
    "\n",
    "Defined by the following formula: $ r_t = \\frac{p_t}{p_{t-1}} -1$ <BR>\n",
    "    \n",
    ">\n",
    "> The percent gain (or loss) if you bought the stock on day and then sold it the next day. <BR>\n",
    "> Very useful in analyzing the volatility of the stock. <BR>\n",
    "> A wide distribution implies the stock is more volatile from one day to the next<BR>\n",
    ">\n",
    "    \n",
    "2 Methods\n",
    "- Use `shift()`\n",
    "- Use built in `pct_change()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Shift\n",
    "df['R_t'] = (df['FB'] / df['FB'].shift(1) ) - 1\n",
    "\n",
    "df['R_t'].plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pct_change\n",
    "df['Pct Chg'] = df['FB'].pct_change()\n",
    "\n",
    "df['Pct Chg'].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Returns = pd.DataFrame()\n",
    "\n",
    "df_Returns['FB'] = df_FB['Close'].pct_change()\n",
    "df_Returns['AMZN'] = df_AMZN['Close'].pct_change()\n",
    "df_Returns['AAPL'] = df_AAPL['Close'].pct_change()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a histogram of the returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Returns['FB'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Returns['AAPL'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack the returns on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "\n",
    "df_Returns['FB'].hist(bins=num_bins, label='FB', figsize=(10,8), alpha = 0.5)\n",
    "df_Returns['AMZN'].hist(bins=num_bins, label='AMZN', figsize=(10,8), alpha = 0.5)\n",
    "df_Returns['AAPL'].hist(bins=num_bins, label='AAPL', figsize=(10,8), alpha = 0.5)\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert a KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Returns['FB'].plot(kind='kde', label='FB', figsize=(10,8))\n",
    "df_Returns['AMZN'].plot(kind='kde', label='AMZN', figsize=(10,8))\n",
    "df_Returns['AAPL'].plot(kind='kde', label='AAPL', figsize=(10,8))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Returns.plot(kind='box', figsize=(8,11), colormap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACD\n",
    "\n",
    "- Turns two moving averages into a momentum oscillator by subtracting the longer moving average from the shorter moving average. \n",
    "- Results in the best of both worlds: trend following and momentum.\n",
    "- MACD formula : (12-day EMA - 26-day EMA)\n",
    "- Uses the pandas ewma function (exponentially weighted moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facebook 2017\n",
    "df_MACD = pd.DataFrame()\n",
    "df_MACD['26 ewm'] = df_FB['2017']['Close'].ewm(span=26).mean()\n",
    "df_MACD['12 ewm'] = df_FB['2017']['Close'].ewm(span=12).mean()\n",
    "df_MACD['MACD'] = df_MACD['12 ewm'] - df_MACD['26 ewm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Co-Variance\n",
    "\n",
    "- Pandas has some convenient built-ins for calculating these.\n",
    "\n",
    "- We'll Use some previous datasets for demonstration.\n",
    "\n",
    "- Calculate the correlation and covariance between the daily percentage change of the Adjusted Close price of FANG Stocks and Gold Futures.\n",
    "\n",
    "- Display the correlation\n",
    "\n",
    "- Calculate the covariance of the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CORR = pd.DataFrame()\n",
    "\n",
    "df_CORR['Facebook'] = df_FB['Close'].pct_change()\n",
    "df_CORR['Apple'] = df_AAPL['Close'].pct_change()\n",
    "df_CORR['Amazon'] = df_AMZN['Close'].pct_change()\n",
    "\n",
    "df_CORR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlation and covariance\n",
    "\n",
    "- Use the **corr()** function\n",
    "- Use the **cov()** function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CORR.corr()\n",
    "\n",
    "# OR for a more recent correlation\n",
    "df_CORR['2017'].corr()\n",
    "\n",
    "# Covariance\n",
    "df_CORR['2017'].cov()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a scatter plot to display a visual of correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "p = scatter_matrix(df_CORR['2017'], alpha=0.9, hist_kwds={'bins':50}, figsize=(18,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rolling Correlations\n",
    "\n",
    "ax = df_CORR['Facebook'].rolling(window=252).corr(df_CORR['Apple']).plot(figsize=(10, 6))  \n",
    "\n",
    "# This line shows the corralation of Facebook and Apple over the entire time period\n",
    "# Note how the rolling correlation is much more telling\n",
    "\n",
    "\n",
    "ax.axhline(df_CORR.corr().iloc[0, 1], c='r');  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rolling Covarianbce\n",
    "\n",
    "ax = df_CORR['Facebook'].rolling(window=252).cov(df_CORR['Apple']).plot(figsize=(10, 6))  \n",
    "\n",
    "# This line shows the covariance of Facebook and Apple over the entire time period\n",
    "# Note how the rolling covariance is much more telling\n",
    "\n",
    "\n",
    "ax.axhline(df_CORR.cov().iloc[0, 1], c='r');  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying functions to Series and DataFrames\n",
    "\n",
    "- You can easily apply arbitrary functions to DataFrames.\n",
    "\n",
    "- Use the **apply()** function\n",
    "\n",
    "- This method can be used to apply a function to a Series, Column, Columns or an entire DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply np.sqrt (square root) to the Close Column of FB\n",
    "df = df_FB.copy()\n",
    "df['Close'].apply(np.sqrt)\n",
    "\n",
    "# Or apply np.cumsum to a set of columns for the year 2017\n",
    "cols = ['Open', 'High', 'Low', 'Close']\n",
    "df['2015':][cols].apply(np.cumsum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Performance \n",
    "\n",
    "Quite often, there are a number of ways of using python to accomplish a particular task.\n",
    "\n",
    "The choice of which to use is often a factor of complexity, personal preferences and simplicity.\n",
    "\n",
    "Occasionally the performance of a particular approach is the main consideration.\n",
    "\n",
    "A fairly common task in financial analysis is to evaluate complex mathematical expressions on large arrays of numbers.\n",
    "\n",
    "Use the %timeit 'magic' to time how long a routine takes\n",
    "\n",
    "e.g. \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\huge 3log(x) + cos(x)^2\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt - Use pure python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "loops = 2500000\n",
    "\n",
    "a = range(1,loops)\n",
    "\n",
    "def f(x):\n",
    "    return 3 * log(x) + cos(x) ** 2\n",
    "\n",
    "%timeit r = [f(x) for x in a]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Attempt - Use numpy\n",
    "\n",
    "The same task can be performed using numpy, which has precompiled functions to handle such operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "loops = 2500000\n",
    "\n",
    "a = range(1,loops)\n",
    "\n",
    "%timeit r = 3 * np.log(a) + np.cos(a) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third attempt - Use numexpr\n",
    "\n",
    "To improve even further, use numexpr, short for numerical expressions.\n",
    "\n",
    "This library compiles expressions for even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "ne.set_num_threads(1)\n",
    "\n",
    "loops = 2500000\n",
    "\n",
    "a = range(1,loops)\n",
    "\n",
    "f = '3 * log(a) + cos(a) ** 2'\n",
    "\n",
    "%timeit r = ne.evaluate(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the performance improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
