{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"120\" src=\"../Images/supplier-logo.png\">\n",
    "<img style=\"float: left; margin-top: 0\" width=\"80\" src=\"../Images/client-logo.png\">\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explain the following topics and concepts:\n",
    "\n",
    "\n",
    "**DataFrames** \n",
    "- Rows and Columns - adding & removing\n",
    "- Adding new columns to a DataFrame\n",
    "- Inserting rows using values calculated from values in other rows\n",
    "- Filtering Data\n",
    "- Sorting Data\n",
    "- Sorting Indexes\n",
    "- Resetting Indexes\n",
    "- Multi Indexes and Cross Sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries\n",
    "\n",
    "Almost every piece of Data Analysis you carry out using python with begin with these 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# format for floats\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in some data from \n",
    "\n",
    "- Use the **read_excel** function to read the contents of a spreadsheet into a DataFrame.\n",
    "\n",
    "\n",
    "** Note **\n",
    "\n",
    "The data we are using in this example came from a single excel file<br>\n",
    "- The excel file has 3 work sheets in it containing price information for 3 companies: Google, IBM and Microsoft\n",
    "- All 3 sheets contain the same type of information: daily trading and stock price information from 2010 to 2017\n",
    "- Each set of data has a Date column, which we will use as our index (More on indexes later)\n",
    "- For this example we have already exported each sheet from excel to its own csv file: Google.csv, IBM.csv, MSFT.csv\n",
    "- We will read in each csv file separately\n",
    "- Later in the course we will cover how to read directly from excel (.xlsx) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL = pd.read_excel('../Data/market_data.xls', sheet_name='GOOGL', index_col='Date', parse_dates=True)\n",
    "df_IBM = pd.read_excel('../Data/market_data.xls', sheet_name='IBM', index_col='Date', parse_dates=True)\n",
    "df_MSFT = pd.read_excel('../Data/market_data.xls', sheet_name='MSFT', index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data\n",
    "\n",
    "Notice in the read_csv function the parameters \n",
    "- index_col='Date' \n",
    "- parse_dates=True\n",
    "\n",
    "**Index_col = 'Date'**<br>\n",
    "- When reading in data from a csv or excel file, you can use the pandas default index or else specify which column you want as your index.\n",
    "- If you use a default then the rows will be labelled numerically, starting at 0\n",
    "- If you pick a column as an index, pandas will use that column as the index.\n",
    "- In this case you have instructed pandas to use the 'Date' column as the index.\n",
    "\n",
    "**parse_dates = True**\n",
    "- This parameter tells pandas to translate anything in the input file that looks like a date into a date data type in the computer's memory.\n",
    "\n",
    "Specifying  these 2 parameters in the **read_csv()** function allows you to use some quite useful selection syntax on your DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>403.97</td>\n",
       "      <td>398.47</td>\n",
       "      <td>399.30</td>\n",
       "      <td>403.50</td>\n",
       "      <td>4346400</td>\n",
       "      <td>403.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-04</th>\n",
       "      <td>411.83</td>\n",
       "      <td>402.90</td>\n",
       "      <td>403.05</td>\n",
       "      <td>411.16</td>\n",
       "      <td>5545600</td>\n",
       "      <td>411.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-05</th>\n",
       "      <td>420.50</td>\n",
       "      <td>414.86</td>\n",
       "      <td>414.88</td>\n",
       "      <td>419.72</td>\n",
       "      <td>8080100</td>\n",
       "      <td>419.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-06</th>\n",
       "      <td>422.42</td>\n",
       "      <td>414.82</td>\n",
       "      <td>420.94</td>\n",
       "      <td>416.11</td>\n",
       "      <td>5740200</td>\n",
       "      <td>416.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-07</th>\n",
       "      <td>418.73</td>\n",
       "      <td>415.21</td>\n",
       "      <td>417.45</td>\n",
       "      <td>416.72</td>\n",
       "      <td>4101200</td>\n",
       "      <td>416.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-08</th>\n",
       "      <td>417.88</td>\n",
       "      <td>412.94</td>\n",
       "      <td>417.67</td>\n",
       "      <td>416.18</td>\n",
       "      <td>5817900</td>\n",
       "      <td>416.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-11</th>\n",
       "      <td>420.27</td>\n",
       "      <td>416.17</td>\n",
       "      <td>416.26</td>\n",
       "      <td>417.83</td>\n",
       "      <td>3186200</td>\n",
       "      <td>417.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-12</th>\n",
       "      <td>416.36</td>\n",
       "      <td>412.25</td>\n",
       "      <td>415.77</td>\n",
       "      <td>414.22</td>\n",
       "      <td>4012500</td>\n",
       "      <td>414.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-13</th>\n",
       "      <td>415.76</td>\n",
       "      <td>411.57</td>\n",
       "      <td>414.36</td>\n",
       "      <td>413.07</td>\n",
       "      <td>3279300</td>\n",
       "      <td>413.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-14</th>\n",
       "      <td>413.91</td>\n",
       "      <td>409.10</td>\n",
       "      <td>413.91</td>\n",
       "      <td>411.18</td>\n",
       "      <td>3299000</td>\n",
       "      <td>411.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-15</th>\n",
       "      <td>410.56</td>\n",
       "      <td>407.08</td>\n",
       "      <td>409.66</td>\n",
       "      <td>407.56</td>\n",
       "      <td>6193200</td>\n",
       "      <td>407.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-18</th>\n",
       "      <td>406.79</td>\n",
       "      <td>401.14</td>\n",
       "      <td>402.90</td>\n",
       "      <td>404.30</td>\n",
       "      <td>3672900</td>\n",
       "      <td>404.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-19</th>\n",
       "      <td>410.04</td>\n",
       "      <td>403.63</td>\n",
       "      <td>406.03</td>\n",
       "      <td>406.07</td>\n",
       "      <td>4192200</td>\n",
       "      <td>406.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-20</th>\n",
       "      <td>409.16</td>\n",
       "      <td>406.13</td>\n",
       "      <td>408.82</td>\n",
       "      <td>407.76</td>\n",
       "      <td>2924600</td>\n",
       "      <td>407.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-21</th>\n",
       "      <td>408.87</td>\n",
       "      <td>405.33</td>\n",
       "      <td>406.05</td>\n",
       "      <td>406.04</td>\n",
       "      <td>2952200</td>\n",
       "      <td>406.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-22</th>\n",
       "      <td>408.03</td>\n",
       "      <td>405.23</td>\n",
       "      <td>407.78</td>\n",
       "      <td>405.56</td>\n",
       "      <td>2973400</td>\n",
       "      <td>405.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-25</th>\n",
       "      <td>410.03</td>\n",
       "      <td>403.81</td>\n",
       "      <td>406.61</td>\n",
       "      <td>405.23</td>\n",
       "      <td>3420500</td>\n",
       "      <td>405.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-26</th>\n",
       "      <td>407.41</td>\n",
       "      <td>404.30</td>\n",
       "      <td>407.16</td>\n",
       "      <td>406.62</td>\n",
       "      <td>2381400</td>\n",
       "      <td>406.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-27</th>\n",
       "      <td>403.90</td>\n",
       "      <td>401.07</td>\n",
       "      <td>403.74</td>\n",
       "      <td>401.73</td>\n",
       "      <td>4322000</td>\n",
       "      <td>401.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-28</th>\n",
       "      <td>403.09</td>\n",
       "      <td>397.05</td>\n",
       "      <td>402.40</td>\n",
       "      <td>397.49</td>\n",
       "      <td>4571000</td>\n",
       "      <td>397.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>401.53</td>\n",
       "      <td>397.02</td>\n",
       "      <td>397.90</td>\n",
       "      <td>401.00</td>\n",
       "      <td>3610900</td>\n",
       "      <td>401.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             High    Low   Open  Close   Volume  Adj Close\n",
       "Date                                                      \n",
       "2013-03-01 403.97 398.47 399.30 403.50  4346400     403.50\n",
       "2013-03-04 411.83 402.90 403.05 411.16  5545600     411.16\n",
       "2013-03-05 420.50 414.86 414.88 419.72  8080100     419.72\n",
       "2013-03-06 422.42 414.82 420.94 416.11  5740200     416.11\n",
       "2013-03-07 418.73 415.21 417.45 416.72  4101200     416.72\n",
       "2013-03-08 417.88 412.94 417.67 416.18  5817900     416.18\n",
       "2013-03-11 420.27 416.17 416.26 417.83  3186200     417.83\n",
       "2013-03-12 416.36 412.25 415.77 414.22  4012500     414.22\n",
       "2013-03-13 415.76 411.57 414.36 413.07  3279300     413.07\n",
       "2013-03-14 413.91 409.10 413.91 411.18  3299000     411.18\n",
       "2013-03-15 410.56 407.08 409.66 407.56  6193200     407.56\n",
       "2013-03-18 406.79 401.14 402.90 404.30  3672900     404.30\n",
       "2013-03-19 410.04 403.63 406.03 406.07  4192200     406.07\n",
       "2013-03-20 409.16 406.13 408.82 407.76  2924600     407.76\n",
       "2013-03-21 408.87 405.33 406.05 406.04  2952200     406.04\n",
       "2013-03-22 408.03 405.23 407.78 405.56  2973400     405.56\n",
       "2013-03-25 410.03 403.81 406.61 405.23  3420500     405.23\n",
       "2013-03-26 407.41 404.30 407.16 406.62  2381400     406.62\n",
       "2013-03-27 403.90 401.07 403.74 401.73  4322000     401.73\n",
       "2013-03-28 403.09 397.05 402.40 397.49  4571000     397.49\n",
       "2013-04-01 401.53 397.02 397.90 401.00  3610900     401.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_GOOGL['2010']\n",
    "df_GOOGL['2012-03']\n",
    "df_GOOGL['2012-MAR']\n",
    "df_GOOGL['2013 march']\n",
    "\n",
    "df_GOOGL['2013 march 01' : '2013 APR 01']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Dual behavior of [] in df[]\n",
    "\n",
    "- When you don't use : inside [], then the value(s) inside it will be considered as column(s).\n",
    "\n",
    "- When you use : inside [], then the value(s) inside it will be considered as row(s).\n",
    "\n",
    "**Why the dual nature?**<br>\n",
    "Because most of the time people want to slice the rows instead of slicing the columns. <br>\n",
    "So they decided that x, y in df[x:y] should correspond to rows and x in d[x] or x, y in df[[x,y]] should correspond to column(s).\n",
    "\n",
    "\n",
    "**Why does df['2017-01-02'] fails?**<br>\n",
    "It will search for a column '2017-01-02', Because there is no such column, it throws an error.\n",
    "\n",
    "**Why does df.loc['2017-01-02'] works then?**<br>\n",
    "Because .loc[] has syntax of df.loc[row,column] and you can leave out the column if you will, as in your case, it simply means df.loc[row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crash and Burn\n",
    "# df_GOOGL['2013 march 01']\n",
    "\n",
    "# to select a singel day\n",
    "df_GOOGL.loc['2013 march 01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new DataFrame\n",
    "\n",
    "Here you are going to create a new DataFrame called df_AdjVol.<br>\n",
    "This DataFrame is going to store the **AdjVolume** for each of IBM, Microsoft and Google.<br>\n",
    "- You will use the pandas DataFrame() function to create the DataFrame and then add 3 new columns to it with names 'IBM', Microsoft' and 'Google'.<br>\n",
    "- You will use the data in the 'AdjVolume' columns from your previous DataFrames to populate your new DataFrame.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Vol = pd.DataFrame()\n",
    "\n",
    "df_Vol['IBM'] = df_IBM['Volume']\n",
    "df_Vol['MSoft'] = df_MSFT['Volume']\n",
    "df_Vol['Google'] = df_GOOGL['Volume']\n",
    "\n",
    "df_Vol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A 50,000 Foot view of a DataFrame\n",
    "\n",
    "Quite often it's useful to get a quick mental image of the rows, columns, size and shape of a DataFrame.\n",
    "\n",
    "Use the shape and size **attributes**.\n",
    "- **shape** returns the number of rows and columns\n",
    "- **size** returns the number of cells (rows * columns)\n",
    "\n",
    "In addition, pandas supplies a useful **function** called **describe()** that prints out some summary information about a DataFrame.\n",
    "\n",
    "Finally, you can use the **transpose()** function on a DataFrame to flip the output around. Transposing a DataFrame may or may not be useful depending on your personal preferences, size and shape of your data, etc.\n",
    "\n",
    "Transposing after a **describe()** can often be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Vol.shape\n",
    "df_Vol.size\n",
    "df_Vol.describe()\n",
    "df_Vol.describe().transpose()\n",
    "df_Vol.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "\n",
    "Filters in a DataFrame allow you to conditionally select data from a DataFrame\n",
    "\n",
    "These are very similar to filters in Excel.\n",
    "\n",
    "syntax is \n",
    "\n",
    "- df[expr]\n",
    "\n",
    "where expr is something that resolves to True or False\n",
    "\n",
    "e.g.<br>\n",
    "- All items where Volume(IBM) > 20000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "TWENTY_MILL = 20 * 1000 * 1000\n",
    "\n",
    "# the filter is simply\n",
    "df_Vol['IBM'] > TWENTY_MILL\n",
    "\n",
    "# and to use the filter on a DataFrame\n",
    "df_Vol [df_Vol['IBM'] > TWENTY_MILL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually a good idea to name filters and to use a consistent easy to understnad naming convention\n",
    "\n",
    "eg. lt (less than), eq (greater than) etc\n",
    "\n",
    "e.g.<br>\n",
    "- All items where Volume(IBM) > 20000000<br>\n",
    "- All items where Volume(Microsoft) < 10000000\n",
    "- All items where Volume(Google) > Volume(IBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TEN_MILL = 10 * 1000 * 1000\n",
    "TWENTY_MILL = 20 * 1000 * 1000\n",
    "\n",
    "# Filters\n",
    "# Volume(IBM) > 20000000\n",
    "ibm_gt_20M = df_Vol['IBM'] > TWENTY_MILL\n",
    "df_Vol[ibm_gt_20M]\n",
    "\n",
    "# Volume(Microsoft) < 10000000\n",
    "msft_lt_10M = df_Vol['MSoft'] < TEN_MILL\n",
    "df_Vol[msft_lt_10M]\n",
    "\n",
    "# Volume(Google) > Volume(IBM)\n",
    "goog_gt_ibm = df_Vol['Google'] > df_Vol['IBM']\n",
    "df_Vol[goog_gt_ibm]\n",
    "\n",
    "# and we can apply functions to the end of a filter\n",
    "df_Vol[goog_gt_ibm].count()\n",
    "\n",
    "# or be more selective - same filter but for the year 2017\n",
    "df_Vol[goog_gt_ibm]['2017']\n",
    "\n",
    "# Filters can be 'ANDed' together using the & symbol\n",
    "# GOOGLE > IBM AND IBM >20M\n",
    "df_Vol[goog_gt_ibm & ibm_gt_20M]\n",
    "\n",
    "# Filters can be 'ORed' together using the | symbol\n",
    "# GOOGLE > IBM AND MS < 10M for the year 2017\n",
    "df_Vol[goog_gt_ibm | msft_lt_10M]['2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new DataFrame\n",
    "\n",
    "This time, rather than loading data in from a file, you are going to create a DataFrame in place, in memory.\n",
    "\n",
    "The code below creates a very simple DataFrame() to illustrate how to work with rows and columns.\n",
    "\n",
    "Do not worry about the syntax, it is quite terse and concise\n",
    "\n",
    "This DataFrame is being used to explain how to add, remove and insert rows and columns into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.arange(16).reshape(4,4)\n",
    "ndx = ['a', 'b', 'c', 'd']\n",
    "cols = ['one','two','three','four']\n",
    "\n",
    "df = pd.DataFrame(data=d, index=ndx, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Rows and Columns\n",
    "\n",
    "A few ways to achieve this, depends on your needs, your style, preferences, data at hand etc.\n",
    "\n",
    "- loc gets rows or columns with particular labels from the index.\n",
    "- iloc gets rows or columns at particular positions in the index (so it only takes integers).\n",
    "- loc and iloc take 2 arguments - row, column\n",
    "- the column argument defaults to all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a row with index label 'c'\n",
    "df.loc['c']\n",
    "\n",
    "# Accessing the 3rd row (index starts at 0)\n",
    "df.iloc[2]\n",
    "\n",
    "# Using loc and ioc to access columns\n",
    "# Need to be a little more specific\n",
    "\n",
    "# Accessing all rows of a column called 'three'\n",
    "df.loc[:, 'three']\n",
    "\n",
    "# Accessing all rows of the 3rd column (index starts at 0)\n",
    "df.iloc[:, 2]\n",
    "\n",
    "# Addressing individual cells\n",
    "df.loc['c','three']\n",
    "df.iloc[2,2]\n",
    "\n",
    "# Accessing columns is usually achieved by specifying the column name\n",
    "df['one']\n",
    "\n",
    "# or the names of columns by using a list\n",
    "df[['two','three']]\n",
    "df[['three','two']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Rows and Columns\n",
    "\n",
    "Three choices\n",
    "\n",
    "- drop (rows and columns)\n",
    "- del (columns only)\n",
    "- pop (columns only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing a row\n",
    "df.drop('b')\n",
    "\n",
    "# Note that dropping returns a new DataFrame, the original is still unchanged\n",
    "df\n",
    "\n",
    "# drop returns the updated DataFrame\n",
    "# often then case that we 'catch' this in another variable, leaving the original unchanged\n",
    "x = df.drop('b')\n",
    "x\n",
    "\n",
    "# Can also drop multiple rows\n",
    "x = df.drop(['b','c'])\n",
    "x\n",
    "\n",
    "# Can use drop to remove a column\n",
    "# Use the axis parameter to specify we are referring to columns\n",
    "x = df.drop('two', axis=1)\n",
    "x\n",
    "\n",
    "# or more descriptively\n",
    "x = df.drop('two', axis='columns')\n",
    "x\n",
    "\n",
    "# Usually drop is for rows and pop is for columns\n",
    "# pop WILL remove a column from the DataFrame\n",
    "# pop returns the column removed \n",
    "# often a good idea to catch the removed column in a new variable \n",
    "x = df.pop('two')\n",
    "x\n",
    "\n",
    "df\n",
    "\n",
    "# del deletes a column and returns nothing\n",
    "# very unforgiving\n",
    "\n",
    "del df['three']\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending Columns\n",
    "\n",
    "\n",
    "- very easy to accomplish\n",
    "- E.g. To add a column populated with **data** to the end of your DataFrame\n",
    "  - df['NAME OF COLUMN'] = **data**\n",
    "- if the column already exists, it will overwrite the values in the existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new colum of 5's \n",
    "# This will append a new column to the DataFrame\n",
    "df['five'] = 5\n",
    "\n",
    "# Add another column which is column 'one' multiplied by column 'four'\n",
    "df['six'] = df['one'] * df['four']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting Columns\n",
    "\n",
    "Insert a column into the Google DataFrame between the 'Close' column and the 'Volume' column.\n",
    "\n",
    "Call this column 'High-Low Spread'\n",
    "\n",
    "Populate it with the difference between 'High' and 'Low'.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Trying to insert a column that already exists will result in an error.\n",
    "\n",
    "If you need to, use drop, pop or del to remove a column before re-inserting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the location where you want the column to exist after insertion\n",
    "# Sequence numbers start at 0, i.e. loc=4 inserts as the 5th column\n",
    "\n",
    "# Before the insertion\n",
    "df_GOOGL.head()\n",
    "\n",
    "# Insert and populate\n",
    "df_GOOGL.insert(loc=4, column='High-Low Spread', value=df_GOOGL['High'] - df_GOOGL['Low'])\n",
    "\n",
    "# After insertion\n",
    "df_GOOGL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Values\n",
    "\n",
    "- Use **sort_values**\n",
    "- Leaves the original unchanged and returns the updated to be caught in a new variable\n",
    "- Can sort by multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the SP500 Constituents and display\n",
    "df_SPX = pd.read_excel(io='../Data/sample_Data.xls', sheet_name='SP500', index_col='Symbol')\n",
    "\n",
    "# Display the unsorted data\n",
    "df_SPX.head(20)\n",
    "\n",
    "\n",
    "# Sort by Name\n",
    "df_SPX.sort_values(by='Name')\n",
    "\n",
    "\n",
    "# Sort by Name - Descending\n",
    "df_SPX.sort_values(by='Name', ascending=False)\n",
    "\n",
    "\n",
    "# Sort by Sector then by Name\n",
    "df_SPX.sort_values(by=['Sector','Name'])\n",
    "\n",
    "\n",
    "# Sometimes multiple columns are stored in a local variable\n",
    "cols = ['Sector', 'Name']\n",
    "df_SPX.sort_values(by=cols)\n",
    "\n",
    "# Sort by Sector Ascending and Price Descending\n",
    "cols = ['Sector', 'Price']\n",
    "directioNs = [True, False]\n",
    "df_SPX.sort_values(by=cols, ascending=directioNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes\n",
    "\n",
    "Indexes are used to 'lookup' rows or columns based on a key.\n",
    "\n",
    "DataFrames have indexes on rows and on columns.\n",
    "\n",
    "For our SP500 Data Set<br>\n",
    "- the column index is Name, Sector, Price .....\n",
    "- the row index is MMM, AOS, ABT ....\n",
    "\n",
    "**Note** \n",
    "- neither index is sorted, they don't need to be.\n",
    "- indexes do not have to be unique, although, more often than not, they are\n",
    "\n",
    "Having Indexes on a DataFrame allows you to\n",
    "- select a column df['Sector']\n",
    "- select a row df.loc['FB']\n",
    "\n",
    "You can drop an index and re-create it using a different set of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Indexes\n",
    "\n",
    "- Different use cases will require data to be sorted differently\n",
    "- This Includes indexes (row indexes and column indexes)\n",
    "- The default for a DataFrame is to have indexes sorted in ascending order\n",
    "- Use sort_index()\n",
    "- This leaves the original DataFrame unchanged and returns you the new DataFrame that you should catch in a new variable\n",
    "\n",
    "**Note**\n",
    "- Some functions can be applied to either rows or columns\n",
    "- A parameter called 'axis' is passed to indicate which you want to operate on (either rows or columns)\n",
    "- You can set 'axis' using the word 'rows' or 'columns' (axis='rows' OR axis='columns')\n",
    "- Alternatively you can use a number: for rows axis=0, for columns axis=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort index will default to sorting the row index\n",
    "df_SPX.sort_index()\n",
    "\n",
    "# Sort descending\n",
    "df_SPX.sort_index(ascending = False)\n",
    "\n",
    "\n",
    "# You can specify sorting the the column index\n",
    "# Assing either 1 or 'columns' to the axis parameter\n",
    "df_SPX.sort_index(axis = 1)\n",
    "\n",
    "df_SPX.sort_index(axis = 'columns', ascending = False)\n",
    "\n",
    "# Sometimes useful to sort columns afgter a transpose\n",
    "df_SPX.transpose().sort_index(axis=1, ascending=True)\n",
    "\n",
    "\n",
    "# Same as previous buyt with a sort of the rows thrown in at the end\n",
    "df_SPX.transpose().sort_index(axis=1, ascending=True).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resetting Indexes\n",
    "\n",
    "We often want to reset an index so that it becomes numerical starting at 0\n",
    "\n",
    "We can also set a column to be the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to default 0,1...n index\n",
    "df_SPX = df_SPX.reset_index()\n",
    "\n",
    "df_SPX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the index to the 'Name' column\n",
    "\n",
    "\n",
    "df_SPX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a multi-index from a file\n",
    "\n",
    "The data in question is in the Protfolios worksheet in the sample_data spreadhseet\n",
    "\n",
    "You are going to create a DataFrame using this file and then create a multi-level index of Rep, then Portfolio and finally Sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Create a DataFrame from the portfolio csv file\n",
    "\n",
    "Note that this will create a DataFrame with a default index - starting at 0 and going up in steps of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read in the file\n",
    "df = pd.read_excel(io='../Data/sample_data.xls', sheet_name='Portfolios')\n",
    "\n",
    "# Just to check that all is in order\n",
    "# You could also try describe(), count, etc.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create a MultiIndex from the Portfolio and Sector columns.\n",
    "\n",
    "- zip - is a python function that creates a python structure called a tuple\n",
    "- list creates a list\n",
    "- combining them gives us a list of tuples\n",
    "\n",
    "Once created, display the tuples to visualize what you have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now zip up the Portfolio and Sector columns\n",
    "tuples = list(zip(df['Rep'], df['Portfolio'],df['Sector']))\n",
    "\n",
    "hier_index = pd.MultiIndex.from_tuples(tuples)        \n",
    "\n",
    "tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Drop the existing index and recreate it using the multi index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally drop the existing index and assign a MultiIndex to the DataFrame\n",
    "df.index = hier_index\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Drop the unwanted columns and rename the indexes\n",
    "\n",
    "Notice that the Portfolio and Sector columns are both present and also part of the index.\n",
    "\n",
    "These two columns can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop('Portfolio')\n",
    "df.pop('Sector')\n",
    "df.pop('Rep')\n",
    "\n",
    "df.index.names = ['Rep', 'Portfolio','Sector']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Cross Section the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All Portfolios where John os the Rep\n",
    "df.xs(key='John', level=0)\n",
    "\n",
    "# Same as above\n",
    "df.xs(key='John', level='Rep')\n",
    "\n",
    "# Get all items in Portfolio P5\n",
    "df.xs(key='P5', level='Portfolio')\n",
    "\n",
    "# Get all items in 'Industrials' \n",
    "df.xs(key='Industrials',level='Sector')\n",
    "\n",
    "# Get all items for Ringo, Portfolio 2, and Energy\n",
    "df.xs(key=['Ringo', 'P2', 'Energy'], level=['Rep', 'Portfolio', 'Sector'])\n",
    "\n",
    "# Same as above except using some variables\n",
    "keys = ['Ringo', 'P2', 'Energy']\n",
    "levels = ['Rep', 'Portfolio', 'Sector']\n",
    "df.xs(key=keys, level=levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
