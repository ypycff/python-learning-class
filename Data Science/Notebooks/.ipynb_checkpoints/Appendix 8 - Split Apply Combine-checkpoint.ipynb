{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"120\" src=\"../Images/supplier-logo.png\">\n",
    "<img style=\"float: left; margin-top: 0\" width=\"80\" src=\"../Images/client-logo.png\">\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis\n",
    "\n",
    "This notebook will explain the following topics and concepts:\n",
    "\n",
    "\n",
    "1) Functions - Basics\n",
    "\n",
    "2) Apply functions to DataFrames\n",
    "\n",
    "3) Vectorized Functions\n",
    "- Using `numpy`\n",
    "- Using `numba`\n",
    "\n",
    "3) Aggregation\n",
    "\n",
    "4) Transformation\n",
    "\n",
    "5) Filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions - Basics\n",
    "\n",
    "A way to group and reuse python code, removes the need to copy/past code.\n",
    "\n",
    "D.R.Y - Dont repeat yourself\n",
    "\n",
    "Use the `def` keyword to define a function\n",
    "\n",
    "Python used indentation to define blocks of code\n",
    "\n",
    "Use the `return` keyword to have the function return a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Function\n",
    "def foo():\n",
    "    # indent 4 spaces\n",
    "    #Â function code here\n",
    "    print(\"Calling Foo\")\n",
    "    \n",
    "    \n",
    "# execute the function\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second function\n",
    "# Have the function return a value\n",
    "\n",
    "def my_sq(n):\n",
    "    return n * n\n",
    "\n",
    "# execute the function\n",
    "my_sq(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Function\n",
    "\n",
    "def my_exp(x, e):\n",
    "    return x ** e\n",
    "\n",
    "# exdecute the function\n",
    "my_exp(6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply (Basics)\n",
    "\n",
    "Use apply to use a fucntion across rows or columns of a DataFrame\n",
    "\n",
    "Use `func` to indentify function to be executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    'a': [10,20,30],\n",
    "    'b': [20,30,40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply over a series\n",
    "\n",
    "**NOTE** <BR>\n",
    "- a column / row in a DataFrame is a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot apply a function that takes ZERO argumentz\n",
    "\n",
    "# This is an error\n",
    "# df['a'].apply(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Parameter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the value in each cell as the argument to the function\n",
    "df['a'].apply(func=my_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Parameter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the value in each cell as the argument to the function\n",
    "# Use the keyword argument to pass in the value for 'e'\n",
    "df['a'].apply(func=my_exp, e=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply over a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_me(x):\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column-wise Operations\n",
    "\n",
    "- `axis=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(func=print_me, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row-wise Operations\n",
    "\n",
    "- `axis=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(func=print_me, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Apply\n",
    "\n",
    "Use the titanic dataset to write more advanced apply operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "df_titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing values in a Series \n",
    "def count_missing(ser):\n",
    "    nulls = pd.isnull(ser)\n",
    "    \n",
    "    return np.sum(nulls)\n",
    "\n",
    "# Proportion of missing values in a Series \n",
    "def prop_missing(ser):\n",
    "    num = count_missing(ser)\n",
    "    den = ser.size\n",
    "    \n",
    "    return num/den\n",
    "\n",
    "# Proportion complete\n",
    "def prop_complete(ser):\n",
    "    return 1 - prop_missing(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is column wise\n",
    "missing = df_titanic.apply(func=count_missing)\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set the column-wise ordering\n",
    "p_missing = df_titanic.apply(func=prop_missing, axis=0)\n",
    "print(p_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rowwise\n",
    "p_complete = df_titanic.apply(func=prop_complete, axis=1)\n",
    "print(p_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple DataFrame\n",
    "\n",
    "- Same as DataFrame at astart of Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    'a': [10,20,30],\n",
    "    'b': [20,30,40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Arithmetic\n",
    "\n",
    "e.g. average of 2 values\n",
    "\n",
    "Note that `pandas` and `numpy` will perform either scalar or vector arithmetic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_2(x,y):\n",
    "    return (x+y)/2\n",
    "\n",
    "# Scalar\n",
    "print(avg_2(10,100))\n",
    "\n",
    "# Vector\n",
    "print(avg_2(df['a'], df['b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Vectorized Arithmetic\n",
    "\n",
    "Not all functions can be automaticall vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def avg_2_modified(x,y):\n",
    "    if (x == 20):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (x + y) / 2\n",
    "\n",
    "# Scalar\n",
    "print(avg_2_modified(10,100))\n",
    "print(avg_2_modified(20,100))\n",
    "\n",
    "# Vectors\n",
    "## Does not compile\n",
    "#print(avg_2_modified(df['a'], df['b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 - Use np.vectorize\n",
    "\n",
    "Use `numpy.vectorize` to change the function so that when given a vector of values, it will perform element-wise calculactions. <BR>\n",
    "\n",
    "Useful in 2 cases\n",
    "\n",
    "1 - When you dont have the source code for the function, use `np.vbectorize()`\n",
    "\n",
    "2 - When you do have the source code for the function, use the `vectorize decorator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1\n",
    "avg_2_mod_vec = np.vectorize(avg_2_modified)\n",
    "\n",
    "# Scalar\n",
    "print(avg_2_mod_vec(10,100))\n",
    "print(avg_2_mod_vec(20,100))\n",
    "\n",
    "# Vectors\n",
    "print(avg_2_mod_vec(df['a'], df['b']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2\n",
    "\n",
    "@np.vectorize\n",
    "def v_avg_2_modified(x,y):\n",
    "    if (x == 20):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (x + y) / 2\n",
    "\n",
    "# Scalar\n",
    "print(v_avg_2_modified(10,100))\n",
    "print(v_avg_2_modified(20,100))\n",
    "\n",
    "# Vectors\n",
    "print(v_avg_2_modified(df['a'], df['b']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 - Use numba\n",
    "\n",
    "Designed to optimize python code, esp on array calculations.\n",
    "\n",
    "- Use the numba vectorize decorator\n",
    "\n",
    "- `numba` does not understand pandas objects so need to convert series and dataframes to arrays\n",
    "\n",
    "- Use the `values` property\n",
    "\n",
    "Same 2 situations as before\n",
    "\n",
    "1 - When you dont have the source code for the function, use `np.vbectorize()`\n",
    "\n",
    "2 - When you do have the source code for the function, use the `vectorize decorator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1\n",
    "avg_mod_2_numba = numba.vectorize(avg_2_modified)\n",
    "\n",
    "# Scalar\n",
    "print(avg_mod_2_numba(10,100))\n",
    "print(avg_mod_2_numba(20,100))\n",
    "\n",
    "# Vectors\n",
    "print(avg_mod_2_numba(df['a'], df['b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2\n",
    "import numba\n",
    "\n",
    "@numba.vectorize\n",
    "def v_avg_2_numba(x,y):\n",
    "    if (x == 20):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return (x + y) / 2\n",
    "\n",
    "# Scalar\n",
    "print(v_avg_2_numba(10,100))\n",
    "print(v_avg_2_numba(20,100))\n",
    "\n",
    "# Vectors\n",
    "print(v_avg_2_numba(df['a'].values, df['b'].values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split-Apply-Combine\n",
    "\n",
    "Referring to a process involving one or more of the following steps:\n",
    "- **Splitting** the data into groups based on some criteria. \n",
    "- **Applying** a function to each group independently. \n",
    "- **Combining** the results into a data structure. \n",
    "\n",
    "Out of these, the split step is the most straightforward. In fact, in many situations we may wish to split the data set into groups and do something with those groups. In the apply step, we might wish to do one of the following:\n",
    "\n",
    "- **Aggregation**: compute a summary statistic (or statistics) for each group. e.g.:\n",
    ">\n",
    ">Compute group sums or means.\n",
    ">Compute group sizes / counts.\n",
    ">\n",
    "\n",
    "- **Transformation**: perform some group-specific computations and return a like-indexed object. e.g.:\n",
    ">\n",
    ">Standardize data (zscore) within a group.\n",
    ">Filling NAs within groups with a value derived from each group.\n",
    ">\n",
    "\n",
    "- **Filtration**: discard some groups, according to a group-wise computation that evaluates True or False. e.g.:\n",
    ">\n",
    ">Discard data that belongs to groups with only a few members.\n",
    ">Filter out data based on the group sum or mean.\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "Process of taking multiple values and returnign a single value <BR>\n",
    "Sometimes referred to as *`summarization`*\n",
    " \n",
    " \n",
    "Some form of reduction is performed by taking multiple values and replacing them with a single value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By\n",
    "\n",
    "Many functions can be applied to the result of GroupBy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas functions\n",
    "- count, size, mean, std, min, quantile, max, sum, var, sem, describe, first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer='../Data/gapminder.tsv', sep='\\t')\n",
    "\n",
    "df.groupby(by='year')['lifeExp'].mean()\n",
    "df.groupby(by='year')['lifeExp'].std()\n",
    "df.groupby(by='year')['lifeExp'].sem()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Pandas Functions\n",
    "Use the `agg` method\n",
    "e.g. for numpy and scipy functions\n",
    "\n",
    "- np.count_nonzero, np.mean, np.std, np.min, np.max, np.percentile, np.sum, np.var\n",
    "- scipy.stats.sem, scipy.stats.describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "df.groupby(by='year')['lifeExp'].agg(np.count_nonzero)\n",
    "df.groupby(by='year')['lifeExp'].agg(np.std)\n",
    "df.groupby(by='year')['lifeExp'].agg(scipy.stats.sem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to calculate mean\n",
    "\n",
    "def my_mean(values):\n",
    "    n = len(values)\n",
    "    sum = 0\n",
    "    for v in values:\n",
    "        sum += v\n",
    "    \n",
    "    return sum / n\n",
    "\n",
    "df.groupby(by='year')['lifeExp'].agg(my_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes mulitple parameters\n",
    "def my_mean_diff(values, diff_value):\n",
    "    n = len(values)\n",
    "    sum = 0\n",
    "    for v in values:\n",
    "        sum += v\n",
    "    mean = sum / n\n",
    "    \n",
    "    return mean - diff_value\n",
    "\n",
    "\n",
    "# Calcualte global average life exp & subtract it form a grouped value\n",
    "global_mean = df['lifeExp'].mean()\n",
    "\n",
    "# Note that python does not like the named paraemeter version\n",
    "# Not exactly sure why this is\n",
    "# df.groupby('year')['lifeExp'].agg(func=my_mean_diff,diff_value=global_mean)\n",
    "\n",
    "# This version using an unmaed parameter works fine\n",
    "df.groupby('year')['lifeExp'].agg(my_mean_diff,diff_value=global_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Functions\n",
    "\n",
    "### Option 1 - Use a list of functions (or some iterable collection of functions)\n",
    "\n",
    "can also use `aggregate(...)` instead of `agg(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [np.std, np.mean, np.count_nonzero]\n",
    "df.groupby('year')['lifeExp'].agg(func_list)\n",
    "\n",
    "# These are the pandas functions\n",
    "func_set = {'std','min', 'max', 'count'}\n",
    "df.groupby('year')['lifeExp'].agg(func_set)\n",
    "\n",
    "# Mix and match\n",
    "func_tup = (my_mean, np.std, 'count')\n",
    "df.groupby('year')['lifeExp'].agg(func_tup)\n",
    "\n",
    "# Mix and match\n",
    "func_tup = (my_mean, np.std, 'count')\n",
    "df.groupby('year')['lifeExp'].aggregate(func_tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 - Use a dict\n",
    "\n",
    "- Use the key of the dict to refer to the column\n",
    "- Use the value to refer to the function to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dict = {\n",
    "    'lifeExp'  : 'mean',\n",
    "    'pop'      : np.std,\n",
    "    'gdpPercap': my_mean\n",
    "}\n",
    "\n",
    "df.groupby('year').aggregate(func_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "Takes a vector of values and performs a 1-2-1 mapping / transformation\n",
    "\n",
    "There is no reduction with transform\n",
    "\n",
    "e.g. the z-Scxore\n",
    "\n",
    "- number of std deviations from the mean\n",
    "\n",
    "- $\\mathbf{ z = \\frac{x - \\mu}{\\sigma} }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_zscore(x):\n",
    "    return (x - x.mean() / x.std())\n",
    "\n",
    "# Transform the data\n",
    "df.groupby(by='year')['lifeExp'].transform(my_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in some data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tips = sns.load_dataset('tips')\n",
    "\n",
    "# Look at table size\n",
    "df_tips['size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 use pandas.filter & user defined function\n",
    "\n",
    "e.g. display only data where each group of table sizes has mroe than 30 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt30(df):\n",
    "    return df['size'].count() >= 30\n",
    "\n",
    "df_tmp = df_tips.groupby(by='size').filter(gt30)\n",
    "\n",
    "df_tmp['size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 use pandas.filter & lambda\n",
    "\n",
    "Same as above but using a lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_tips.groupby(by='size').filter(lambda x: x['size'].count() >= 30)\n",
    "\n",
    "df_tmp['size'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
