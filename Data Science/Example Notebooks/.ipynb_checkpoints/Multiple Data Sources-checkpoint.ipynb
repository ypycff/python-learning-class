{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"120\" src=\"../Images/supplier-logo.png\">\n",
    "<img style=\"float: left; margin-top: 0\" width=\"80\" src=\"../Images/client-logo.png\">\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "Aswell as importing data into DataFrames from files such as csv or excel spreadsheets\n",
    "\n",
    "Users can also import data from other soruces\n",
    "\n",
    "This notebook shows a few \n",
    "\n",
    "- WebScraping\n",
    "\n",
    "- Quandl - An online Data providers\n",
    "\n",
    "- Relational Databases - sqlite\n",
    "\n",
    "- Exporting Data to Excel\n",
    "\n",
    "- Sending Emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Federal Reserve of New York\n",
    "\n",
    "Import over night rates into a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# the python package to follow a URL and return its results\n",
    "import requests\n",
    "\n",
    "# beautiful soup - for web scraping\n",
    "import bs4 as bs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data \n",
    "\n",
    "Get the response from the web page\n",
    "\n",
    "Convert it to `soup`\n",
    "\n",
    "Find the table we are looking for and store it in a local variable (`table`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('https://apps.newyorkfed.org/markets/autorates/fed%20funds')\n",
    "\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "table = soup.find('table', {'id':'TBLDetails'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the table from soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "rates = []\n",
    "p1s = []\n",
    "p25s = []\n",
    "p75s = []\n",
    "p99s = []\n",
    "vols = []\n",
    "targets = []\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "for row in table.findAll('tr')[2:]:\n",
    "    \n",
    "    dt = str(now.year) + \"/\" + row.findAll('td')[0].text.split()[0]\n",
    "    \n",
    "    dates.append(dt)\n",
    "    if len(row.findAll('td')) == 9:\n",
    "        rates.append(row.findAll('td')[1].text.split()[0])\n",
    "        p1s.append(row.findAll('td')[2].text.split()[0][20:25].replace(\"'\",\"\"))\n",
    "        p25s.append(row.findAll('td')[3].text.split()[0][20:25].replace(\"'\",\"\"))\n",
    "        p75s.append(row.findAll('td')[4].text.split()[0][20:25].replace(\"'\",\"\"))\n",
    "        p99s.append(row.findAll('td')[5].text.split()[0][20:25].replace(\"'\",\"\"))    \n",
    "        vols.append(row.findAll('td')[6].text.split()[0])\n",
    "    \n",
    "        ts = row.findAll('td')[7].text.split()\n",
    "        target = ts[0]+ts[1]+ts[2]\n",
    "        targets.append(target)\n",
    "    else:\n",
    "        rates.append(\"0.0\")\n",
    "        p1s.append(\"0.0\")\n",
    "        p25s.append(\"0.0\")\n",
    "        p75s.append(\"0.0\")\n",
    "        p99s.append(\"0.0\")  \n",
    "        vols.append(\"0.0\")\n",
    "        targets.append(\"0.0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the lists of data to populate a datframe\n",
    "\n",
    "Need to change the datatypes from strings \n",
    "- to numeric\n",
    "- to dates\n",
    "- also note that I need to use the str replace function to massage the volumne column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Date'] = dates\n",
    "df['Rate'] = pd.to_numeric(rates)\n",
    "df['1st PCile'] = pd.to_numeric(p1s)\n",
    "df['25th PCile'] = pd.to_numeric(p25s)\n",
    "df['75th PCile'] = pd.to_numeric(p75s)\n",
    "df['99th PCile'] = pd.to_numeric(p99s)\n",
    "df['Target Range'] = targets\n",
    "df['Vol'] = vols\n",
    "\n",
    "df['Vol'] = pd.to_numeric(df['Vol'].str.replace(',', ''))\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df.index = df['Date']\n",
    "\n",
    "del df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to excel and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "fname = 'fedfunds' + now.strftime('%Y%m%d') + '.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(path=fname, engine='xlsxwriter')\n",
    "\n",
    "# Convert the DataFrame to an XlsxWriter Excel object.\n",
    "# In this case we'll put each of the FANG columns in a separate sheet.\n",
    "df.to_excel(writer, sheet_name='Fed Funds')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "Extract the stock tickers for the SP500 from Wikipedia into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the python package to follow a URL and return its results\n",
    "import requests\n",
    "\n",
    "# beautiful soup - for web scraping\n",
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "table = soup.find('table', {'class':'wikitable sortable'})\n",
    "\n",
    "tickers = []\n",
    "\n",
    "for row in table.findAll('tr')[1:]:\n",
    "    ticker = row.findAll('td')[0].text\n",
    "    tickers.append(ticker)\n",
    "\n",
    "tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "Second method, read all tables directly into a pandas DataFrame.\n",
    "\n",
    "\n",
    "Use the pandas function `read_html(...)`, pass it a url and it will return a list of dataframes, each dataframe contining the contents of each table in the url.\n",
    "\n",
    "THis is very basic but reasonably satisfactory, tho a user will need to expend some effort in chanign names of columns, the datatypes of idividual cells etc.\n",
    "\n",
    "\n",
    "For the wiki paage above, `read_html(...)` returns 2 dataframes, one for each table it found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "print(\"Number of tables on page: \", len(dfs))\n",
    "\n",
    "for df in dfs:\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Data from the internet\n",
    "\n",
    "There is a plethora of web sites, web services that allow users to download all sorts of data in all manner of formats.\n",
    "\n",
    "e.g. Manual, Automated excel format, pdfs, word, json, csv and text and DataFrames!!!\n",
    "\n",
    "A very good website is https://www.quandl.com/\n",
    "\n",
    "This offers good quality data for free and for a fee.\n",
    "\n",
    "Log on, register and download data in a variety of formats.\n",
    "\n",
    "To use their APIs you need an api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries\n",
    "\n",
    "And set the quandle key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "\n",
    "quandl.ApiConfig.api_key = \"YOIR API KEY HERE\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.get('NSE/RELIANCE', start_date = '2017-JAN-01', end_date='2019-JAN-24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.get('NSE/RELIANCE', start_date = '2017-JAN-01', end_date='2019-JAN-24')\n",
    "quandl.get('OPEC/ORB', start_date='2009-01-23', end_date='2019-01-24')\n",
    "quandl.get('LBMA/GOLD', start_date='2018-01-01', end_date='2019-01-23')\n",
    "quandl.get('WIKI/IBM', start_date='2018-01-01', end_date='2019-01-23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a simple function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(start, end, symbol):\n",
    "    data = 'WIKI/'+ symbol\n",
    "\n",
    "    return quandl.get(dataset = data, start_date = start, end_date = end)\n",
    "\n",
    "df = getData(\"2000-01-01\", \"2018-12-31\",\"C\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "df[['Close']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLLite\n",
    "\n",
    "Use the flights database located in `../Data/DataBase/flights.db`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries\n",
    "\n",
    "And connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"../Data/flights.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a cursor frpm the database\n",
    "\n",
    "Use the connection object ot get a cursor.\n",
    "\n",
    "cursors allow users to exdcute SQL against the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute some SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"select * from airlines limit 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `fetchall()` to view the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cur.fetchall()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are a list of uples\n",
    "\n",
    "\n",
    "Users can chain the `execute()` and `fetchall()` methods together if they wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"select * from airlines limit 5;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished with the connections and cursors, rememebr to **close** them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading results into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"../Data/flights.db\")\n",
    "df = pd.read_sql_query(\"select * from airlines limit 5;\", conn)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting rows with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"insert into airlines values (6048, 19846, 'Test flight', '', '', null, null, null, 'Y')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing parameters into a query\n",
    "\n",
    "Use `?` and a values parameter<br>\n",
    "Any `?` value in the query will be replaced by a value in values. <br>\n",
    "The first `?` will be replaced by the first item in values, the second by the second, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "values = ('Test Flight', 'Y')\n",
    "cur.execute(\"insert into airlines values (6049, 19847, ?, '', '', null, null, null, ?)\", values)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "values = ('USA', 19847)\n",
    "cur.execute(\"update airlines set country=? where id=?\", values)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test to verify the update happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"select * from airlines where id=19847;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "values = [19847]\n",
    "cur.execute(\"delete from airlines where id=?\", values)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test to verify the update happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"select * from airlines where id=19847;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data to Excel\n",
    "\n",
    "\n",
    "We use the Pandas ExcelWriter function to output a DataFrame or Series to an Excel spreadsheet.\n",
    "\n",
    "We can choose what data goes into each sheet in the Excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the famous FANG stocks\n",
    "filename = '../Data/market_data.xls'\n",
    "df_FB = pd.read_excel(io=filename, parse_dates=True, index_col='Date', sheet_name='FB')\n",
    "df_AAPL = pd.read_excel(io=filename, parse_dates=True, index_col='Date', sheet_name='AAPL')\n",
    "df_AMZN = pd.read_excel(io=filename, parse_dates=True, index_col='Date', sheet_name='AMZN')\n",
    "df_NFLX = pd.read_excel(io=filename, parse_dates=True, index_col='Date', sheet_name='NFLX')\n",
    "df_GOOGL = pd.read_excel(io=filename, parse_dates=True, index_col='Date', sheet_name='GOOGL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. the daily returns\n",
    "df_Returns = pd.DataFrame()\n",
    "\n",
    "# Calculate the log of daily returns\n",
    "df_Returns['FB'] = np.log(df_FB['Close'] / df_FB['Close'].shift(-1))\n",
    "df_Returns['AAPL'] = np.log(df_AAPL['Close'] / df_AMZN['Close'].shift(-1))\n",
    "df_Returns['AMZN'] = np.log(df_AMZN['Close'] / df_AMZN['Close'].shift(-1))\n",
    "df_Returns['NFLX'] = np.log(df_NFLX['Close'] / df_NFLX['Close'].shift(-1))\n",
    "df_Returns['GOOGL'] = np.log(df_GOOGL['Close'] / df_GOOGL['Close'].shift(-1))\n",
    "\n",
    "# Do some aggregation functions\n",
    "funcs = ['min', 'max', 'mean', 'std']\n",
    "grpr = pd.Grouper(freq='BQ')\n",
    "\n",
    "df = df_Returns.groupby(grpr).agg(funcs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Data to an excel Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('../Output/FAANG.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the DataFrame to an XlsxWriter Excel object.\n",
    "# In this case we'll put each of the FANG columns in a separate sheet.\n",
    "df['FB'].to_excel(writer, sheet_name='FB')\n",
    "df['AAPL'].to_excel(writer, sheet_name='AAPL')\n",
    "df['AMZN'].to_excel(writer, sheet_name='AMZN')\n",
    "df['NFLX'].to_excel(writer, sheet_name='NFLX')\n",
    "df['GOOGL'].to_excel(writer, sheet_name='GOOGL')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "# Check that the data has been correctly saved to a file called 'FANG.xlsx' in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emailing\n",
    "\n",
    "Treat these as templates\n",
    "\n",
    "They use smtp to connect ot an email server rather than outlook.#\n",
    "\n",
    "#Using outlook is somewhat restrtictive, it requires outlook to be installed on the host machine etc\n",
    "\n",
    "This way the code is more portable\n",
    "\n",
    "\n",
    "The domain name for the SMTP server is usually the name of your email providers domain name with **smtp.** in front of it\n",
    "\n",
    "Ports are almost always 587\n",
    "\n",
    "| Provider |  SMTP server domain name   |\n",
    "|------|------|\n",
    "|   Gmail  | smtp.gmail.com|\n",
    "|   Outlook.com/Hotmail.com   | smtp-mail.outlook.com|\n",
    "|   Yahoo Mail  | smtp.mail.yahoo.com|\n",
    "|   iCloud   | smtp.mail.me.com|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) Emailing Simple messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "import email.mime.application\n",
    "\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "FROM = \"someone@somewhere.com\"\n",
    "TO = \"someone_else@someplace_else.com\"\n",
    "SUBJECT = \"Results of Technical Analysis v2\"\n",
    "PASSWD = \"PASSWORD\"\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "\n",
    "msg['From'] = FROM\n",
    "msg['To'] = TO\n",
    "msg['Subject'] = SUBJECT\n",
    "\n",
    "# The body of an email is just an attachment, the same as any other attachment\n",
    "BODY = \"\"\"Resutls from last nights run\n",
    "\n",
    "Regards\n",
    "\n",
    "Pat\n",
    "\"\"\"\n",
    "msg.attach(MIMEText(BODY, 'plain'))\n",
    "\n",
    "# Send the message\n",
    "HOST = \"smtp-mail.outlook.com\"\n",
    "PORT = \"587\"\n",
    "SERVER = smtplib.SMTP(HOST, PORT)\n",
    "\n",
    "SERVER.starttls()\n",
    "SERVER.login(FROM, PASSWD)\n",
    "text = msg.as_string()\n",
    "SERVER.sendmail(FROM, TO, text)\n",
    "SERVER.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emailing attachments\n",
    "\n",
    "Use `MIMEMultipart.attach()` to attach a file or text to an email message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "import email\n",
    "import email.mime.application\n",
    "\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "FROM = \"someone@somewhere.com\"\n",
    "TO = \"someone_else@someplace_else.com\"\n",
    "SUBJECT = \"Results of Technical Analysis v2\"\n",
    "PASSWD = \"PASSWORD\"\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "\n",
    "msg['From'] = FROM\n",
    "msg['To'] = TO\n",
    "msg['Subject'] = SUBJECT\n",
    "\n",
    "# The body of an email is just an attachment, the same as any other attachment\n",
    "BODY = \"\"\"Resutls from last nights run\n",
    "\n",
    "Regards\n",
    "\n",
    "Pat\n",
    "\"\"\"\n",
    "msg.attach(MIMEText(BODY, 'plain'))\n",
    "\n",
    "# PDF attachment\n",
    "filename='../Data/pdf_1.pdf'\n",
    "fp=open(filename,'rb')\n",
    "att = email.mime.application.MIMEApplication(fp.read(),_subtype=\"pdf\")\n",
    "fp.close()\n",
    "att.add_header('Content-Disposition','attachment',filename=\"PDF Version.pdf\")\n",
    "msg.attach(att)\n",
    "\n",
    "# Word attachment\n",
    "filename='../Data/doc_1.docx'\n",
    "fp=open(filename,'rb')\n",
    "att = email.mime.application.MIMEApplication(fp.read(),_subtype=\"docx\")\n",
    "fp.close()\n",
    "att.add_header('Content-Disposition','attachment',filename=\"Word Version.docx\")\n",
    "msg.attach(att)\n",
    "\n",
    "# csv attachment\n",
    "filename='../Data/FB.csv'\n",
    "fp=open(filename,'rb')\n",
    "att = email.mime.application.MIMEApplication(fp.read(),_subtype=\"text/csv\")\n",
    "fp.close()\n",
    "att.add_header('Content-Disposition','attachment',filename=\"Facebook.csv\")\n",
    "msg.attach(att)\n",
    "\n",
    "# Send the message\n",
    "HOST = \"smtp-mail.outlook.com\"\n",
    "PORT = \"587\"\n",
    "SERVER = smtplib.SMTP(HOST, PORT)\n",
    "\n",
    "SERVER.starttls()\n",
    "SERVER.login(FROM, PASSWD)\n",
    "text = msg.as_string()\n",
    "SERVER.sendmail(FROM, TO, text)\n",
    "SERVER.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
