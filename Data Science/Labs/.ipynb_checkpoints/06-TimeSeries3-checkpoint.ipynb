{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this lab you’ll use the SARIMA model that you built in the previous lab to predict and forecast values in the time series (we’ll explain the difference between predictions and forecasts shortly).\n",
    "\n",
    "You’ll also use various diagnostic information available to verify the goodness-of-fit of the SARIMA model.\n",
    "\n",
    "# Roadmap\n",
    "There are 3 exercises in this lab, of which the last exercise is \"if time permits\". Here is a brief summary of the tasks you will perform in each exercise; more detailed instructions follow later:\n",
    "1.\tPlotting diagnostic information about how well the model fits the data\n",
    "2.\tUsing the model to predict values\n",
    "3.\t(If time permits) Using the model to forecast future values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "input_file = './Data/CO2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1:  Plotting diagnostic info about how well the model fits the data\n",
    "\n",
    "The MLEResults object returned by the fit() function has a very handy method named plot_diagnostics(), which plots various graphs that enable you to determine how well the model fits the data. Call the plot_diagnostics() method as follows:\n",
    "\n",
    "    results.plot_diagnostics()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s an explanation of the 4 graphs on the previous page:\n",
    "-\tThe upper-left graph shows the standardized residual values. The term “residual” means the difference between the actual value (in the time series data) and the value predicted by the model. There is always a difference between actual and predicted values – this is unavoidable, even if your model is great! What you’re looking for is the absence of any systematic pattern (e.g. residual values that increase over time or show a cyclical pattern). \n",
    "In our case, there is no pattern to the residual data; the “errors” seem evenly distributed. Sometimes the residual value is positive, sometimes it’s negative. There isn’t any systemic discrepancy between actual and predicted values, which suggests the model is good!\n",
    "-\tThe upper-right graph shows 3 plots:\n",
    ">\tN(0,1) plot, which is a perfect normal distribution (i.e. a mean of 0 and a standard deviation of 1). \n",
    ">\n",
    ">\tKDE (Kernel Density Estimation) plot, which shows the density of standardized residuals. The KDE plot is very close to the N(0,1) plot, which means the residuals exhibit a near-normal distribution with no particular bias and with a small range of residual errors, which suggests the model is good!\n",
    ">\n",
    ">\tA histogram that shows the same info as the KDE plot, but as a histogram rather than as a curve.\n",
    "-\tThe lower-left graph shows a Normal Q-Q (Quantile-Quantile) plot. The red line shows what the residuals should look like if they were perfectly normally distributed. The blue dots show the residuals yielded by our model. As you can see, the blue dots are very close to the red line, which means the residuals are normally distributed, which suggests the model is good!\n",
    "_\tThe lower-right graph shows a Correlogram (autocorrelation) plot for the residuals. The plot indicates there is no correlation between residual values, i.e. our model doesn’t yield any systemic relationship between residuals, which suggests the model is good!\n",
    "\n",
    "These graphs are incredibly important. It’s vital that you know whether your model is a good or bad fit for the data, so that you can have confidence in using the model to predict and forecast future values.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:  Using the model to predict values\n",
    "\n",
    "\n",
    "In the previous exercise you verified that the model is a good fit for the data, so it’s safe to use the model to predict/forecast new values. The MLEResults object has two methods for this purpose:\n",
    "-\tget_prediction() predicts values within the date/time range of the time series. You can then compare these predicted values with the actual values in the time series, to see if the model has done a good job of modelling reality. You’ll see how to do all this in this exercise.\n",
    "-\tget_forecast() forecasts values outside the date/time range of the time series. You’ll see how to that in next exercise.\n",
    "Let’s see how to use get_prediction() to predict values within the date/time range of the time series. Full documentation about the get_prediction() function is available here:\n",
    "\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.mlemodel.MLEResults.get_prediction.html\n",
    "\n",
    "Let’s say you want to predict CO2 levels for 1997 onwards. You can achieve this as follows:\n",
    "    prediction = results.get_prediction(start='1997-01-01')\n",
    "\n",
    "The function returns a prediction object. The prediction object has a conf_int() method that gives you the predicted lower and upper CO2 value for each period, to 95% confidence. This info is expressed as a DataFrame with 3 columns: the date/time index; the lower predicted value; and the upper predicted value. Try out the following code to see what it looks like:\n",
    "\n",
    "    prediction_ci = prediction.conf_int()\n",
    "    print('\\nRange of predicted values\\n', prediction_ci)\n",
    "    print('\\nLower predicted values\\n',    prediction_ci.iloc[:, 0])\n",
    "    print('\\nUpper predicted values\\n',    prediction_ci.iloc[:, 1])\n",
    "\n",
    "The prediction object also has a predicted_mean property that gives you the mean predicted CO2 value for each period. Try out the following code:\n",
    "\n",
    "    prediction_mean = prediction.predicted_mean         \n",
    "    print('\\nMean predicted values\\n', prediction_mean)\n",
    " \n",
    "As well as seeing predicted values printed on the console, it’s also very useful to visualize the predicted values on a plot. You’ll do that now…\n",
    "First, add the following code to create a plot for the actual values, e.g. for 1990 onwards:\n",
    "\n",
    "    ts1990onwards = ts['1990' : ]\n",
    "    axes = ts1990onwards.plot(label='Actual values')\n",
    "    axes.set_xlabel('Date')\n",
    "    axes.set_ylabel('CO2')\n",
    "\n",
    "Note that the plot() function returns a MatPlotLib Axes object, which represents the axes upon which the current plot (i.e. the actual values) is drawn. You can use this Axes object to superimpose additional plots; for example, the following code superimposes the predicted mean values on the same axes (the predicted values will be drawn in red here, with an opacity of 75%):\n",
    "\n",
    "    prediction_mean.plot(ax=axes,\n",
    "                         label='Mean predicted values', \n",
    "                         color='red',\n",
    "                         alpha=0.75)\n",
    "                         \n",
    "It’s also informative to plot the range of values between the lower and upper values in the 95% confidence range. You can use the fill_between() function to do this, as shown below. The 1st parameter specifies x values, and the 2nd and 3rd parameters specify the lower and upper y values to fill-in (in fairly transparent black, in this example):\n",
    "\n",
    "    axes.fill_between(prediction_ci.index,\n",
    "                      prediction_ci.iloc[:, 0],\n",
    "                      prediction_ci.iloc[:, 1],\n",
    "                      color='black', \n",
    "                      alpha=0.25)\n",
    "All that remains is to show these plots, along with a legend:\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (If time permits):  Using the model to forecast future values\n",
    "\n",
    "In the previous exercise you used the get_prediction() function to predict values within the date/time range of the time series. \n",
    "\n",
    "In this exercise you’ll use the get_forecast() function to forecast values outside the date/time range of the time series, i.e. to forecast future values. get_forecast() is very similar to get_prediction() – it obtains lower and upper forecast values with 95% confidence, and also a predicted mean value. Full details about the function are available here:\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.mlemodel.MLEResults.get_forecast.html\n",
    "\n",
    "Add code to your script to forecast CO2 values for 200 months beyond the end of the current time series. When you’re done, plot the information as follows. Note that the confidence range diverges as time goes on, which is to be expected – the further into the future you forecast, the less certain you can be about the forecast:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
