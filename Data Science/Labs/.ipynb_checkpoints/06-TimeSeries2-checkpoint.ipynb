{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this lab you’ll continue working with the CO2 data that you saw in the previous lab. The focus now will be on determining whether the time series data is stationary, and building an ARIMA model that explains the data. \n",
    "\n",
    "In fact, you’ll build a SARIMA model (the S prefix stands for Seasonal). SARIMA is much better than ARIMA when dealing with data that has a high degree of seasonality. We’ll explain the details as the lab unfolds.\n",
    "\n",
    "# Roadmap\n",
    "There are 5 exercises in this lab, of which the last exercise is \"if time permits\". Here is a brief summary of the tasks you will perform in each exercise; more detailed instructions follow later:\n",
    "1.\tDetermining whether time series data is stationary\n",
    "2.\tPerforming differencing on time series data\n",
    "3.\tPlotting ACF and PACF graphs\n",
    "4.\tDetermining parameters to model time series data using SARIMA\n",
    "5.\t(If time permits) Additional suggestions\n",
    " \n",
    "# Familiarization\n",
    "A condensed outline of the steps in this lab are:\n",
    "-\tFirst, we call read_csv() to read the CO2 data into a Pandas DataFrame object. We indicate that the date column should be the index for the DataFrame.\n",
    "-\tNext, we extract the co2 column from the DataFrame into a Panda Series object. It’s easier to manipulate a single-column Series than a multi-column DataFrame.\n",
    "-\tNext up, we call fillna() to fill in the holes in the data. Generally, it’s good to avoid having holes in time series data.\n",
    "-\tFinally, we call resample() to resample the data into monthly groups, and we then call mean() to calculate the mean value for each month. The motivation here is to reduce the size of the dataset, to make it more manageable.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = './Data/CO2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1:  Determining whether time series data is stationary\n",
    "\n",
    "Stationarity is a vital concept when dealing with time series data. If time series data is stationary, or can be made stationary via suitable mathematical massaging, then you can confidently predict values into the future.\n",
    "\n",
    "The first step is to determine whether the CO2 data is stationary. There are two ways to determine do this:\n",
    "-\tPlot the data and see if it looks stationary. This is always a good start, because it helps you get a better understanding of the data. \n",
    "-\tTest the data statistically, e.g. using an Augmented Dickey-Fuller test. This is always worth doing too, because it gives you a more formal indication on whether the data is stationary. \n",
    "\n",
    "We showed how to do both these things during the chapter, and we implemented a function named display_stationarity_info() to encapsulate all the steps. We’ve made this function available in the student folder too.\n",
    "\n",
    "Call display_stationarity_info() from your code to plot the graph of C01 over time.\n",
    "\n",
    "Display ADF statistical information on the console.\n",
    "\n",
    "\n",
    "With an ADF test, the null hypothesis is that the data is non-stationary. This is how you interpret the results of the ADF test:\n",
    "-\tIf the ADF statistic is less than the critical values, you can reject the null hypothesis. This would mean the data is stationary.\n",
    "-\tIf the ADF statistic is greater than the critical values, you can’t reject the null hypothesis. This would mean the data is non-stationary.\n",
    "\n",
    "In our case, the ADF statistic is much bigger than any of the critical values, so the CO2 data is non-stationary. We kinda knew that anyway from the graph, but sometimes it’s not quite so easy to decide just by looking at a graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:  Performing differencing on time series data\n",
    "\n",
    "In the previous exercise you ascertained that the CO2 data is non-stationary. This is generally the case for most time series data. The next challenge is to decide how to make it stationary. We discussed several ways to do this during the chapter:\n",
    "-\tTake the log of the data. This can be a reasonable first step to reduce trend, but it’s rarely enough to eliminate all non-stationarity, so we won’t do it for the CO2 data.\n",
    "-\tCalculate the moving average or exponentially weighted moving average of the data. These techniques can be useful for eliminating trend, but not so good at eliminating seasonality.\n",
    "-\tPerform differencing to eliminate trend. For example, subtract the previous 1 term (for 1st-order differencing), subtract the previous 2 terms (for 2nd-order differencing) etc. \n",
    "-\tYou can also perform differencing to eliminate seasonality. For example, if you know the seasonality is 12 months, then you can subtract the term 12 months ago (for 1st-order seasonal differencing), subtract the terms 12 and 24 months ago (for 2nd-order seasonal differencing) etc. \n",
    "\n",
    "For now, we’ll focus on differencing to remove trend (later in this lab, we’ll take a look at how to perform differencing to remove seasonality using SARIMA modelling)… \n",
    "\n",
    "Write python code  to investigate 1st-order differencing, 2nd-order differencing, and 3rd-order differencing. Call display_stationarity_info() in each case, and examine the ADF statistics \n",
    "\n",
    "These results indicate that 1st-order differencing is sufficient to achieve stationarity. Generally, you want the smallest amount of differencing that is sufficient to give an ADF statistic that is smaller than the critical values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3:  Plotting ACF and PACF graphs\n",
    "\n",
    "In the previous exercise, you saw that 1st-order differencing can achieve stationarity in terms of trend (the graphs showed that 1st-order difference flattens the overall increasing trend in the data).\n",
    "\n",
    "The next step is to build a model that explains how values in the time series are related to previous values in the time series. ARIMA is a very popular modelling technique, as we discussed in the chapter. The ARIMA function requires 3 parameters:\n",
    "- p – Auto-Regressive term\n",
    "- d – Differencing term (the previous exercise suggested a value of 1 for this) \n",
    "- q – Moving Average term\n",
    "\n",
    "To establish a suitable value for p and q, call the plot_pacf() and plot_acf() functions respectively. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation graph shows a clear correlation at 12-monhtly cycles. This indicates a high degree of seasonality in the data, i.e. the way CO2 values fluctuate during a year is a repeating pattern. This might be due to seasonal climatic conditions, length of days, local manufacturing processes, or some other factor – but there is clearly something going on here.\n",
    " \n",
    "It turns out that ARIMA doesn’t cope very well with seasonal data. Rather, you should use SARIMA (the S prefix stands for Seasonal). The following exercise describes how SARIMA works and explains how to use it in Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4:  Determining parameters to model time series data using SARIMA\n",
    "\n",
    "SARIMA is an excellent way to model time series data that has a strong seasonal element. It’s a superset of ARIMA and requires the following information:\n",
    "-\tp, d, q \t- Same as for ARIMA, to model adjacent values within a season. \n",
    "-\tP, D, Q \t- Similar to p, d, q in ARIMA, but to model values across seasons.\n",
    "-\ts\t- Number of periods in a season, e.g. 12 months in a year season.\n",
    "\n",
    "To do SARIMA modelling in Python, use the SARIMAX() function in the statsmodels library. You’ll need the following import statement:\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "You can call the SARIMAX() function as follows:\n",
    "\n",
    "`model = SARIMAX(ts, order=oparam, seasonal_order=soparam , enforce_stationarity=False, enforce_invertibility=False)`\n",
    "                \n",
    "Here’s an explanation of the keyword parameters:\n",
    "-\torder is a tuple containing the (p,d,q) values – the same as for ARIMA.\n",
    "-\tseasonal_order is a tuple containing the (P,D,Q,s) values that describe the seasonal relationship between values.\n",
    "-\tenforce_stationarity is a Boolean flag indicating that you don’t want the SARIMAX() function to enforce stationarity.\n",
    "-\tenforce_invertibility is a Boolean flag indicating that you don’t want the SARIMAX() function to enforce invertibility.\n",
    "\n",
    "When you use SARIMAX() to create a model for your seasonal data, you have to decide what values for the (p,d,q) and (P,D,Q,s) hyperparameters create the best model of the data. One way to find the best values for (p,d,q) and (P,D,Q,s) is to do a “grid search”, i.e. loop through all the feasible combinations of (p,d,q) and (P,D,Q,s) values and see which give the best model fit. \n",
    "\n",
    "The first step is to create a list of (p,d,q) tuples containing feasible combinations of values for p, d, q. The following code shows how to do this for the values 0…1. (For more info about the itertools Python module, see https://docs.python.org/3/library/itertools.html): \n",
    "\n",
    "    import itertools\n",
    "\n",
    "    p = d = q = range(0, 2)\n",
    "\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "    print('\\npdq combinations\\n', pdq) \n",
    "\n",
    "\n",
    "The next step is to create a list of (P,D,Q,s) tuples where P, D, Q is 0 or 1, and where s=12 in each case (we know there are 12 periods in each season). The following code does the trick: \n",
    "\n",
    "    PDQs = [(x[0], x[1], x[2], 12) for x in pdq]\n",
    "\n",
    "    print('\\nPDQs combinations\\n', PDQs)\n",
    "\n",
    "You can now plug each combination of tuples in pdq and PDQs into the SARIMAX() function, to see which combination gives the best model fit. Use the following code to do this:\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "for oparam in pdq:\n",
    "\n",
    "    for soparam in PDQs:\n",
    "    \n",
    "        try:\n",
    "        \n",
    "            model = SARIMAX(ts,\n",
    "            \n",
    "                            order=oparam,\n",
    "                            \n",
    "                            seasonal_order=soparam,\n",
    "                            \n",
    "                            enforce_stationarity=False,\n",
    "                            \n",
    "                            enforce_invertibility=False)\n",
    "                            \n",
    "            results = model.fit(disp=0)\n",
    "\n",
    "            print('SARIMAX(order={}, seasonal_order={}), AIC={}'.\n",
    "                  format(oparam, soparam, results.aic))           \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "Note the following points:\n",
    "-\tSARIMAX() builds a mathematical model for the data, and returns a model object.\n",
    "-\tWe call fit() on the model object, to fit the model to the data. The function returns a results object that provides statistical info about how well the model describes the data.\n",
    "-\tThe results object has an aic property (Akaike Information Criterion). Without going into all the math, the smaller the aic value, the better the fit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (If time permits):  Additional suggestions\n",
    "\n",
    "In the previous exercise you printed all the results from the SARIMAX() function in pdq/PDQs order. You then had to hunt through all the results to see which one gave the smallest aic value.\n",
    "A better approach would be to output the results in aic order, so you can immediately see which result has the smallest aic. Enhance your code to do this. Here are some high-level hints:\n",
    "-\tBefore the loops, create an empty list.\n",
    "-\tOn each iteration, insert a new item into the list to capture the pdq tuple, the PDQs tuple, and the aic result of the model fit.\n",
    "-\tAfter the loops have finished, sort the list based on the aic values.\n",
    "-\tPrint the sorted list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
